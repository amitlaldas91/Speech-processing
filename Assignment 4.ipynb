{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0802b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d43ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file\n",
    "audio_file_path = \"abc.wav\"\n",
    "with wave.open(audio_file_path, 'rb') as wave_file:\n",
    "    sample_rate = wave_file.getframerate()\n",
    "    num_channels = wave_file.getnchannels()\n",
    "    num_frames = wave_file.getnframes()\n",
    "    audio_signal = np.frombuffer(wave_file.readframes(num_frames), dtype=np.int16)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b949ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the audio signal to [-1, 1]\n",
    "audio_signal = audio_signal / (2.0 ** 15)\n",
    "\n",
    "# Compute the Pitch (F0) using autocorrelation\n",
    "autocorr = np.correlate(audio_signal, audio_signal, mode='full')\n",
    "autocorr = autocorr[autocorr.size // 2:]\n",
    "f0_index = np.argmax(autocorr[sample_rate // 500:sample_rate // 75]) + sample_rate // 500\n",
    "f0 = sample_rate / f0_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Formants (F1, F2, F3) using LPC analysis\n",
    "ncoeffs = 2 + sample_rate // 1000\n",
    "A = np.zeros((ncoeffs, ncoeffs))\n",
    "for i in range(ncoeffs):\n",
    "    for j in range(ncoeffs):\n",
    "        A[i, j] = autocorr[np.abs(i - j)]\n",
    "coeffs = np.linalg.solve(A[1:], -A[0])\n",
    "roots = np.roots(np.concatenate(([1], coeffs)))\n",
    "roots = roots[np.imag(roots) >= 0]\n",
    "angz = np.arctan2(np.imag(roots), np.real(roots))\n",
    "formants = sorted(angz * sample_rate / (2 * np.pi))\n",
    "\n",
    "# Plot the results\n",
    "times = np.arange(0, num_frames / sample_rate, 1 / sample_rate)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(times, audio_signal, label='Speech Signal')\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(times[:len(autocorr)], autocorr, label='Autocorrelation')\n",
    "plt.axvline(x=f0_index / sample_rate, linestyle='--', color='red', label='Pitch (F0)')\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(times[:len(angz)], formants[:3], label='Formants (F1-F3)')\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.ylim(0, 5000)\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddd1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import scipy.io.wavfile as wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3535f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pitch_shift' from 'pydub.effects' (C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\effects.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract the fundamental frequency (F0) using the \"To Pitch\" function\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#pitch = sound.to_pitch()\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meffects\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pitch_shift\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Load audio file\u001b[39;00m\n\u001b[0;32m     17\u001b[0m audio \u001b[38;5;241m=\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39mfrom_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabc.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pitch_shift' from 'pydub.effects' (C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\effects.py)"
     ]
    }
   ],
   "source": [
    "# Load the audio signal from a .wav file\n",
    "filename = \"abc.wav\"\n",
    "sampling_freq, signal_data = wavfile.read(filename)\n",
    "\n",
    "# Convert the signal to float data type\n",
    "signal_data = signal_data.astype(np.float64)\n",
    "\n",
    "# Create a Parselmouth Sound object\n",
    "sound = parselmouth.Sound(signal_data, sampling_freq)\n",
    "\n",
    "# Extract the fundamental frequency (F0) using the \"To Pitch\" function\n",
    "#pitch = sound.to_pitch()\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import pitch_shift\n",
    "\n",
    "# Load audio file\n",
    "audio = AudioSegment.from_file(\"abc.wav\", format=\"wav\")\n",
    "# Shift the pitch up by 12 semitones (1 octave)\n",
    "pitched_audio = audio.apply_effect(pitch_shift, 12)\n",
    "\n",
    "# Get the pitch information\n",
    "pitch = pitched_audio.dBFS\n",
    "\n",
    "\n",
    "# Extract the formants (F1, F2, and F3) using the \"To Formant\" function\n",
    "formants = sound.to_formant()\n",
    "\n",
    "# Convert the Parselmouth objects to numpy arrays\n",
    "f0 = pitch.selected_array['frequency']\n",
    "time_axis = pitch.xs()\n",
    "formant1 = formants['frequency'][0]\n",
    "formant2 = formants['frequency'][1]\n",
    "formant3 = formants['frequency'][2]\n",
    "\n",
    "# Plot the Pitch (F0) and formants (F1, F2, and F3)\n",
    "time_vector = np.arange(len(signal_data)) / sampling_freq\n",
    "plt.plot(time_vector, f0, label=\"Pitch (F0)\")\n",
    "plt.plot(time_vector, formant1, label=\"Formant F1\")\n",
    "plt.plot(time_vector, formant2, label=\"Formant F2\")\n",
    "plt.plot(time_vector, formant3, label=\"Formant F3\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.title(\"Pitch and Formants\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eceedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
